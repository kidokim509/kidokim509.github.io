---
title:   CDH5에서 Spark 2.x 돌리기
date:    2018-10-23 17:20:00 +0900
categories: [dev, spark]
tags: [cdh5, spark]
---

## 사전 준비
spark submit 목적의 gateway (개발 PC)에 설치를 진행
hadoop client가 이미 설치되어 hadoop cluster와 잘 연동되고 있다고 가정
- $HADOOP_HOME
- $HADOOP_CONF_DIR: hadoop cluster의 폴더 구조와 동일하게
- $HIVE_HOME
- $HIVE_CONF_DIR: hadoop cluster의 폴더 구조와 동일하게
Spark 설정은 yarn-cluster mode 기준

## Spark Client 설치
yarn cluster가 java7을 사용하면 spark 2.1.X를, java8을 사용하면 2.2.0 이상 사용
[https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html)
위 사이트에서 "Pre-build with user-provided Apache Hadoop"으로 다운로드 받아서 임의의 위치에 압축을 푼다.

# Spark Client 설치 및 설정
```shell
$ wget https://archive.apache.org/dist/spark/spark-2.1.3/spark-2.1.3-bin-without-hadoop.tgz
$ tar xvzf spark-2.1.3-bin-without-hadoop.tgz
$ export SPARK_HOME=spark-2.1.3-bin-without-hadoop
$ cd $SPARK_HOME
$ cp spark-defaults.conf.template spark-defaults.conf
$ vim ./spark-defaults.conf
spark.driver.extraJavaOptions  -XX:+PrintGCDetails -XX:MaxPermSize=1024m
spark.yarn.jars                hdfs://nameservice/app/spark/jars/*
$ cp ./spark-env.sh.tempate spark-env.sh
export SPARK_DIST_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):/opt/cloudera/parcels/CDH/lib/hive/lib/*:/etc/hive/conf
```
Worker Node에는 Spark 2.x Jar가 없기 때문에, HDFS에 필요한 jar 파일들을 넣어놓고, spark.yarn.jars를 설정

# HDFS에 yarn에서 Spark Job 실행 시 필요한 jar 복사
- $SPARK_HOME/jars
- http://repository.cloudera.com/artifactory/cloudera-repos/org/apache/spark/ 에서 아래 파일 다운로드
  - spark-hive_2.11-2.1.0.clouderaX.jar
  - spark-hive-exec_2.11-2.1.0.clouderaX.jar
```shell
$ hadoop fs -put $SPARK_HOME/jars hdfs://nameservices/app/spark
$ hadoop fs -put spark-hive_2.11-2.1.0.clouderaX.jar hdfs://nameservices/app/spark/jars
$ hadoop fs -put spark-hive-exec_2.11-2.1.0.clouderaX.jar hdfs://nameservices/app/spark/jars
```
